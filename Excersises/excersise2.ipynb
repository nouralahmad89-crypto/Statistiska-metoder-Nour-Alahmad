{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ae40f7",
   "metadata": {},
   "source": [
    "# Excersise 1:\n",
    "A sensor in a smart network has a probability p = .7 to correctly detect a person entering a\n",
    "room.\n",
    "1.  If 10 people enter the room, how many detections are expected?\n",
    "2.  If 12 people enter the room, what is the probability that between 2 and 7 people are detected?\n",
    "3.  If 3 people are detected, what’s the likelihood that 5 people entered the room?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65901b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Expected value is  7.0\n",
      "probability that between 2 and 7 people detected is 0.2763291186810001\n",
      "likelihood that 5 people detected is 0.30869999999999986 \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "# 1) probability= 0.7 (detected) p=0.3( not detected)\n",
    "n= 10\n",
    "p= 0.7\n",
    "# expected value\n",
    "print(f\" Expected value is  {n*p}\")\n",
    "\n",
    "#2) probability between 2 and 7 people are detected\n",
    "n= 12\n",
    "prob= binom.cdf(7 , n, p) - binom.cdf( 1, n , p)\n",
    "print(f\"probability that between 2 and 7 people detected is {prob}\")\n",
    "\n",
    "# 3) calculate likelihood\n",
    "n= 5\n",
    "x= 3\n",
    "likeli= binom.pmf( x, n, p)\n",
    "print(f\"likelihood that 5 people detected is {likeli} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8466208",
   "metadata": {},
   "source": [
    "# Excersie 2\n",
    "A large random sample from an unknown distribution is drawn. The mean is calculated to be 0\n",
    "and the standard deviation is 1.\n",
    "1.  What kind of distributions could the sample have been drawn from?\n",
    "2.  What’s the probablility that a normally distributed random variable will lie within one, two\n",
    "and three standard deviations from its mean?\n",
    "Consider the smart network sensors in the previous exercise. Across 120 common rooms, a total\n",
    "of 24000 people move through an office complex per day.\n",
    "3. How many detections are expected per day?\n",
    "4.  How many detections would be considered unusually few?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ae8c62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " probability that a normally random variable lie with 1 is 0.6826894921370859\n",
      " probability that a normally random variable lie with 2 is 0.9544997361036416\n",
      " probability that a normally random variable lie with 3 is 0.9973002039367398\n",
      " 16800.0 detection per day\n",
      "16587.0211 usually few\n"
     ]
    }
   ],
   "source": [
    "# 1) normal distribution\n",
    "\n",
    "# 2) caalculate probabilities between 1,2 and 3\n",
    "from scipy.stats import norm\n",
    "\n",
    "for k in [ 1, 2, 3]:\n",
    "    prob= norm.cdf(k)- norm.cdf(-k)\n",
    "    print(f\" probability that a normally random variable lie with {k} is {prob}\")    \n",
    "# 3) expected value , detection per day\n",
    "n= 24000\n",
    "p= 0.7\n",
    "expected= n*p\n",
    "print(f\" {expected} detection per day\")   \n",
    "\n",
    "# 4) unusally few detections\n",
    "mu= binom.mean( n, p)\n",
    "sigma= binom.std(n,p)\n",
    "few_detect= mu- 3*sigma\n",
    "print(f\"{few_detect:.4f} usually few\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92024c1",
   "metadata": {},
   "source": [
    "# Excersise 3\n",
    "During a heavy traffic scenario, it was found that the probability of successfully logging on to a\n",
    "network router at any point was 70%.\n",
    "1.  Is it unusual if two attempts are required to log in during heavy traffic?\n",
    "2.  What is the likelihood of observing (exactly) three attempts?\n",
    "3.  At what point does the number of attempts become unusual? note: These are statistical\n",
    "arguments relying on the Central Limit Theorem, c.f. probabilistic arguments as in the book\n",
    "exercise 3.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n",
      "0.06300000000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(2.993493021443332)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) the answer is No\n",
    "from scipy.stats import geom\n",
    "\n",
    "p= 0.7\n",
    "prob_le= geom.cdf(2,p)\n",
    "prob= geom.pmf(2,p)\n",
    "print(prob_le)\n",
    "# 2) \n",
    "prob_3 = geom.pmf(3, p)  # Probability of exactly 3 attempts\n",
    "print(prob_3)\n",
    "# 3) \n",
    "mu= geom.mean(p)\n",
    "sigma= geom.std(p)\n",
    "s=mu+2*sigma\n",
    "s # The number of attempts becomes unusual at 3 attempts, and rare at 4 or more attempts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41cbfd",
   "metadata": {},
   "source": [
    "# Excersise 4\n",
    "\n",
    "As a follow-up to the heavy traffic scenario, a system was devised that would automatically log\n",
    "in to a number of routers in order to retain monitoring and control in case of network congestion.\n",
    "12 routers are part of the system. The logins are independent of each other. The probability of\n",
    "a successful login attempt remains as p = .7.\n",
    "1. How many attempts are expected before all 12 systems are connected?\n",
    "2. What is the probability of exactly needing 12 attempts?\n",
    "3. In a reasonable worst-case scenario, how many attempts could be expected to be required?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e215dc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.142857142857146\n",
      "0.013841287200999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(25.274428269004407)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1)\n",
    "from scipy.stats import nbinom\n",
    "\n",
    "r= 12\n",
    "p= 0.7\n",
    "mean_failure= nbinom.mean(r,p)\n",
    "mean_attempts= mean_failure + r\n",
    "print(mean_attempts)\n",
    "# 2) \n",
    "0.7**12\n",
    "pb=nbinom.pmf(0,r,p)\n",
    "print(pb)\n",
    "\n",
    "# 3)\n",
    "mu_fail=nbinom.mean(r,p)\n",
    "std_fail= nbinom.std(r,p)\n",
    "mu_attempts= mu_fail + r\n",
    "std_attempts= std_fail\n",
    "worst=mu_attempts +3 * std_attempts\n",
    "worst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Statistiska-metoder-Nour-Alahmad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
